# ğŸ§  DebugIQ Backend

The backend for **DebugIQ**, an autonomous debugging and patching agent platform built using **FastAPI**, powered by **GPT-4o**, **Gemini**, and multi-agent orchestration.

This service is responsible for diagnosis, patch suggestion, QA validation, auto-documentation, pull request creation, and agent workflow orchestration.

---

## ğŸš€ Features

* ğŸ¤– **Autonomous Multi-Step Workflows** (`run_autonomous_workflow.py`)
* ğŸ§  DebugIQ voice bi-directional + chat

  * Root cause analysis
  * Patch generation (diff + explanation)
  * QA validation + result interpretation
  * Auto-documentation and PR prep
* ğŸ”— GitHub PR creation (stubbed / production-ready)
* ğŸ“Š Agent & workflow metrics via `/metrics/status`
* ğŸ—ƒï¸ Mock in-memory issue database (`scripts.mock_db`)
* ğŸ“¦ Modular architecture â€” plug-and-play agents

---

## ğŸ§± Architecture

FastAPI
â”‚
â”œâ”€â”€ /app
â”‚ â””â”€â”€ api/
â”‚ â”œâ”€â”€ autonomous\_router.py # Orchestrated endpoints
â”‚ â”œâ”€â”€ metrics\_router.py # Agent metrics
â”‚ â”œâ”€â”€ issues\_router.py # Inbox / triage endpoints
â”‚ â”œâ”€â”€ voice\_ws\_router.py # Voice (WebSocket)
â”‚ â””â”€â”€ voice\_interactive\_router.py # Voice (text/audio via Gemini)
â”‚
â”œâ”€â”€ /scripts
â”‚ â”œâ”€â”€ run\_autonomous\_workflow\.py # ğŸ§  Core agent pipeline
â”‚ â”œâ”€â”€ platform\_data\_api.py # DB/metadata fetchers
â”‚ â”œâ”€â”€ agent\_suggest\_patch.py # Patch LLM agent
â”‚ â”œâ”€â”€ autonomous\_diagnose\_issue.py # Root cause agent
â”‚ â”œâ”€â”€ validate\_proposed\_patch.py # QA validator
â”‚ â”œâ”€â”€ create\_fix\_pull\_request.py # PR creator
â”‚ â””â”€â”€ mock\_db.py # In-memory issue tracker

yaml
Copy
Edit

---

## ğŸŒ API Endpoints

| Endpoint                   | Method | Description                    |
| -------------------------- | ------ | ------------------------------ |
| `/health`                  | GET    | Health check                   |
| `/workflow/diagnose`       | POST   | Run diagnosis agent            |
| `/suggest-patch`           | POST   | Run patch agent                |
| `/workflow/triage`         | POST   | Triage raw issue data          |
| `/workflow/seed`           | POST   | Seed mock issue into memory    |
| `/run_autonomous_workflow` | POST   | Run full AI â†’ QA â†’ PR workflow |
| `/metrics/status`          | GET    | Agent + issue metrics (JSON)   |
| `/issues/inbox`            | GET    | List all new issues            |
| `/issues/attention-needed` | GET    | Show issues needing review     |

---

## ğŸ› ï¸ Running Locally

```bash
# From the backend root
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000
ğŸŒ Deployment Notes
Component	Notes
API Gateway	Mounted via / or behind proxy (e.g. Vercel, Render)
Voice WS	Enable WebSocket support if running Gemini voice
CORS	Open in dev, restrict for production
GitHub Integration	Stubbed in create_fix_pull_request.py â€” integrate your token and org logic

ğŸ“¦ Environment Variables
Name	Purpose
OPENAI_API_KEY	For GPT-4o interactions
GEMINI_API_KEY	For Gemini agents & voice
GITHUB_TOKEN	For pull request automation

ğŸ§ª Seed Mock Issue Example
json
Copy
Edit
POST /workflow/seed

{
  "issue_id": "ISSUE-001",
  "title": "App crash on login",
  "description": "Login fails when username has emoji",
  "error_message": "UnicodeEncodeError",
  "logs": "...stack trace...",
  "relevant_files": ["auth.py"],
  "repository": "https://github.com/your-org/repo"
}
ğŸ§  Powered By
OpenAI GPT-4o

Gemini Pro

FastAPI

Streamlit Dashboard

Discover Software Solutions Here is what we have for the backend Readme 
```


# ğŸ§  DebugIQ Backend

The backend for **DebugIQ**, an autonomous debugging and patching agent platform built using **FastAPI**, powered by **GPT-4o**, **Gemini**, and multi-agent orchestration.

This service is responsible for diagnosis, patch suggestion, QA validation, auto-documentation, pull request creation, and agent workflow orchestration.

---

## ğŸš€ Features

* ğŸ¤– **Autonomous Multi-Step Workflows** (`run_autonomous_workflow.py`)
* ğŸ§  DebugIQ voice bi-directional + chat

  * Root cause analysis
  * Patch generation (diff + explanation)
  * QA validation + result interpretation
  * Auto-documentation and PR prep
* ğŸ”— GitHub PR creation (stubbed / production-ready)
* ğŸ“Š Agent & workflow metrics via `/metrics/status`
* ğŸ—ƒï¸ Mock in-memory issue database (`scripts.mock_db`)
* ğŸ“¦ Modular architecture â€” plug-and-play agents

---

## ğŸ§± Architecture

FastAPI
â”‚
â”œâ”€â”€ /app
â”‚ â””â”€â”€ api/
â”‚ â”œâ”€â”€ autonomous\_router.py # Orchestrated endpoints
â”‚ â”œâ”€â”€ metrics\_router.py # Agent metrics
â”‚ â”œâ”€â”€ issues\_router.py # Inbox / triage endpoints
â”‚ â”œâ”€â”€ voice\_ws\_router.py # Voice (WebSocket)
â”‚ â””â”€â”€ voice\_interactive\_router.py # Voice (text/audio via Gemini)
â”‚
â”œâ”€â”€ /scripts
â”‚ â”œâ”€â”€ run\_autonomous\_workflow\.py # ğŸ§  Core agent pipeline
â”‚ â”œâ”€â”€ platform\_data\_api.py # DB/metadata fetchers
â”‚ â”œâ”€â”€ agent\_suggest\_patch.py # Patch LLM agent
â”‚ â”œâ”€â”€ autonomous\_diagnose\_issue.py # Root cause agent
â”‚ â”œâ”€â”€ validate\_proposed\_patch.py # QA validator
â”‚ â”œâ”€â”€ create\_fix\_pull\_request.py # PR creator
â”‚ â””â”€â”€ mock\_db.py # In-memory issue tracker

yaml
Copy
Edit

---

## ğŸŒ API Endpoints

| Endpoint                   | Method | Description                    |
| -------------------------- | ------ | ------------------------------ |
| `/health`                  | GET    | Health check                   |
| `/workflow/diagnose`       | POST   | Run diagnosis agent            |
| `/suggest-patch`           | POST   | Run patch agent                |
| `/workflow/triage`         | POST   | Triage raw issue data          |
| `/workflow/seed`           | POST   | Seed mock issue into memory    |
| `/run_autonomous_workflow` | POST   | Run full AI â†’ QA â†’ PR workflow |
| `/metrics/status`          | GET    | Agent + issue metrics (JSON)   |
| `/issues/inbox`            | GET    | List all new issues            |
| `/issues/attention-needed` | GET    | Show issues needing review     |

---

## ğŸ› ï¸ Running Locally

```bash
# From the backend root
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000
ğŸŒ Deployment Notes
Component	Notes
API Gateway	Mounted via / or behind proxy (e.g. Vercel, Render)
Voice WS	Enable WebSocket support if running Gemini voice
CORS	Open in dev, restrict for production
GitHub Integration	Stubbed in create_fix_pull_request.py â€” integrate your token and org logic

ğŸ“¦ Environment Variables
Name	Purpose
OPENAI_API_KEY	For GPT-4o interactions
GEMINI_API_KEY	For Gemini agents & voice
GITHUB_TOKEN	For pull request automation

ğŸ§ª Seed Mock Issue Example
json
Copy
Edit
POST /workflow/seed

{
  "issue_id": "ISSUE-001",
  "title": "App crash on login",
  "description": "Login fails when username has emoji",
  "error_message": "UnicodeEncodeError",
  "logs": "...stack trace...",
  "relevant_files": ["auth.py"],
  "repository": "https://github.com/your-org/repo"
}
ğŸ§  Powered By
OpenAI GPT-4o

Gemini Pro

FastAPI

Streamlit Dashboard

Discover Software Solutions Here's what we have for the backend Readme
```
