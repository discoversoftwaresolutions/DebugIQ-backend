# ğŸ§  DebugIQ Backend

The backend for **DebugIQ**, an autonomous debugging and patching agent platform built using **FastAPI**, powered by **GPT-4o**, **Gemini**, and multi-agent orchestration.

This service is responsible for diagnosis, patch suggestion, QA validation, auto-documentation, pull request creation, and agent workflow orchestration.

---

## ğŸš€ Features

- ğŸ¤– **Autonomous Multi-Step Workflows** (`run_autonomous_workflow.py`)
- ğŸ§  DebugIQ voice bi-directional + chat
  - Root cause analysis
  - Patch generation (diff + explanation)
  - QA validation + result interpretation
  - Auto-documentation and PR prep
- ğŸ”— GitHub PR creation (stubbed / production-ready)
- ğŸ“Š Agent & workflow metrics via `/metrics/status`
- ğŸ—ƒï¸ Mock in-memory issue database (`scripts.mock_db`)
- ğŸ“¦ Modular architecture â€” plug-and-play agents

---

## ğŸ§± Architecture

FastAPI
â”‚
â”œâ”€â”€ /app
â”‚ â””â”€â”€ api/
â”‚ â”œâ”€â”€ autonomous_router.py # Orchestrated endpoints
â”‚ â”œâ”€â”€ metrics_router.py # Agent metrics
â”‚ â”œâ”€â”€ issues_router.py # Inbox / triage endpoints
â”‚ â”œâ”€â”€ voice_ws_router.py # Voice (WebSocket)
â”‚ â””â”€â”€ voice_interactive_router.py # Voice (text/audio via Gemini)
â”‚
â”œâ”€â”€ /scripts
â”‚ â”œâ”€â”€ run_autonomous_workflow.py # ğŸ§  Core agent pipeline
â”‚ â”œâ”€â”€ platform_data_api.py # DB/metadata fetchers
â”‚ â”œâ”€â”€ agent_suggest_patch.py # Patch LLM agent
â”‚ â”œâ”€â”€ autonomous_diagnose_issue.py # Root cause agent
â”‚ â”œâ”€â”€ validate_proposed_patch.py # QA validator
â”‚ â”œâ”€â”€ create_fix_pull_request.py # PR creator
â”‚ â””â”€â”€ mock_db.py # In-memory issue tracker

yaml
Copy
Edit

---

## ğŸŒ API Endpoints

| Endpoint                       | Method | Description                          |
|-------------------------------|--------|--------------------------------------|
| `/health`                     | GET    | Health check                         |
| `/workflow/diagnose`          | POST   | Run diagnosis agent                  |
| `/suggest-patch`              | POST   | Run patch agent                      |
| `/workflow/triage`            | POST   | Triage raw issue data                |
| `/workflow/seed`              | POST   | Seed mock issue into memory          |
| `/run_autonomous_workflow`    | POST   | Run full AI â†’ QA â†’ PR workflow       |
| `/metrics/status`             | GET    | Agent + issue metrics (JSON)         |
| `/issues/inbox`               | GET    | List all new issues                  |
| `/issues/attention-needed`    | GET    | Show issues needing review           |

---

## ğŸ› ï¸ Running Locally

```bash
# From the backend root
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000
ğŸŒ Deployment Notes
Component	Notes
API Gateway	Mounted via / or behind proxy (e.g. Vercel, Render)
Voice WS	Enable WebSocket support if running Gemini voice
CORS	Open in dev, restrict for production
GitHub Integration	Stubbed in create_fix_pull_request.py â€” integrate your token and org logic

ğŸ“¦ Environment Variables
Name	Purpose
OPENAI_API_KEY	For GPT-4o interactions
GEMINI_API_KEY	For Gemini agents & voice
GITHUB_TOKEN	For pull request automation

ğŸ§ª Seed Mock Issue Example
json
Copy
Edit
POST /workflow/seed

{
  "issue_id": "ISSUE-001",
  "title": "App crash on login",
  "description": "Login fails when username has emoji",
  "error_message": "UnicodeEncodeError",
  "logs": "...stack trace...",
  "relevant_files": ["auth.py"],
  "repository": "https://github.com/your-org/repo"
}
ğŸ§  Powered By
OpenAI GPT-4o

Gemini Pro

FastAPI

Streamlit Dashboard

Discover Software Solutions
